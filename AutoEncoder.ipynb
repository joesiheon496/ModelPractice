{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8c/F4qVnoQVaZUs1Lso74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joesiheon496/ModelPractice/blob/master/AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrz96fPNwz4i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv('m10lm/movies.dat', sep =\"::\", header = None, engine='python',encoding='latin-1')\n",
        "users = pd.read_csv('m10lm/users.dat', sep =\"::\", header = None, engine='python',encoding='latin-1')\n",
        "ratings = pd.read_csv('m10lm/ratings.dat', sep =\"::\", header = None, engine='python',encoding='latin-1')"
      ],
      "metadata": {
        "id": "JRqcHRar1beR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = pd.read_csv('u1.base',sep='\\t')\n",
        "training_set = np.array(training_set, dtype='int')\n",
        "\n",
        "test_set = pd.read_csv('u1.base',sep='\\t')\n",
        "test_set = np.array(test_set, dtype='int')"
      ],
      "metadata": {
        "id": "PjuwdhFu26xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_users = int(max(max(training_set[:,0]),max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]),max(test_set[:,1])))"
      ],
      "metadata": {
        "id": "qVIbUXRt-BMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users+1):\n",
        "        id_movies = data[:,1][data[:,0] == id_users]\n",
        "        id_ratings = data[:,2][data[:,0] == id_users]\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        ratings[id_movies-1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data"
      ],
      "metadata": {
        "id": "VaHtgwNzI6La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "metadata": {
        "id": "IC7vj_tLOsWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "X7uMLGMPO5LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAE(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(SAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        self.fc2 = nn.Linear(20,10)\n",
        "        self.fc3 = nn.Linear(10,20)\n",
        "        self.fc4 = nn.Linear(20,nb_movies)\n",
        "        self.activation = nn.Sigmoid()\n",
        "    def forward(self,x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.activation(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yCAQJqrqP_Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sae = SAE()"
      ],
      "metadata": {
        "id": "XqYNH0DwjJXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(sae.parameters(),lr = 0.01, weight_decay = 0.5)"
      ],
      "metadata": {
        "id": "xlOQCN28jUbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epoch = 200\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(nb_users ):\n",
        "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "        target = input.clone()\n",
        "        if torch.sum(target.data>0)>0:\n",
        "            output = sae(input)\n",
        "            target.require_grad = False\n",
        "            output[target == 0] = 0\n",
        "            loss = criterion(output, target)\n",
        "            mean_corrector = nb_movies/float(torch.sum(target.data > 0)+ 1e-10)\n",
        "            loss.backward()\n",
        "            train_loss += np.sqrt(loss.data[0]*mean_corrector)\n",
        "            s += 1.\n",
        "            optimizer.step()\n",
        "    print(f'epoch : {str(epoch)} loss : {str(train_loss / s)}')"
      ],
      "metadata": {
        "id": "l3QrKLmgj986"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users ):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    if torch.sum(target.data>0)>0:\n",
        "        output = sae(input)\n",
        "        target.require_grad = False\n",
        "        output[target == 0] = 0\n",
        "        loss = criterion(output, target)\n",
        "        mean_corrector = nb_movies/float(torch.sum(target.data > 0)+ 1e-10)\n",
        "        loss.backward()\n",
        "        test_loss += np.sqrt(loss.data[0] * mean_corrector)\n",
        "        s += 1.\n",
        "print(f'test_loss : {str(test_loss/s)}')"
      ],
      "metadata": {
        "id": "vxqqC3i6p1bH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}